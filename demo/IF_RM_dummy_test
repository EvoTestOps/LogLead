
import numpy as np
from sklearn.ensemble import IsolationForest
from sklearn.feature_extraction.text import CountVectorizer
import sys
sys.path.append('..')
from loglead.anomaly_detection import RarityModel

# Training data

#Minimal
train_data = [
    "e1",
    "e2",
    "e3"
]
#Small
train_data = [
    "e1",
    "e2",
    "e3",
    "e1",
    "e2",
]
#Realistic
train_data = [
    "e1",
    "e2",
    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2",    "e1",
    "e2", "e3"
]

# Test data
test_data = [
    "e1",
    "e2",
    "e1",
    "e5", #Unseen 
    "e4", #Unseen
    "e3", #Rare in training 
]

# Vectorization of the data
vectorizer = CountVectorizer()
X_train = vectorizer.fit_transform(train_data)
X_test = vectorizer.transform(test_data)

# Isolation Forest
clf = IsolationForest(random_state=42)
clf.fit(X_train)

# Predict anomaly scores
scores = clf.decision_function(X_test)
anomalies = clf.predict(X_test)
# Display results
for text, score, anomaly in zip(test_data, scores, anomalies):
    print(f"Text: {text}\nScore: {score:.2f}, Anomaly: {anomaly}\n")



rm = RarityModel(common_threshold=0.2)
rm.fit(X_train)
#Rarity model
anomalies = rm.predict(X_test)
# Display results
anomalies
#rm.scores