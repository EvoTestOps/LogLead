# exclusions:
# # This crashes Python on laptop. Most likely out of memory
#   - parser: Brain
#     dataset: Hdfs
#     proportion: 1/1

datasets:
  Hadoop:
    filename: "/hadoop/"
    filename_pattern: "*.log"
    labels_file_name: "/hadoop/abnormal_label_accurate.txt"
    loader: "HadoopLoader"
    proportion: 1/1 #How much of the data is used. 
    proportion_redraws: 1 #How many times we want to redraws the data. If proportion 1/1 then set this to 1. 
    test_fraction: 0.5 #How much data is used for testing from the proportion, e.g. if proportion 1/10 and test_fraction 0.10  -> 9% is used for training and 1% for testing
    chronological_order : False #Do we maintain chrological order when splitting for train and test. For real data with long real world duration use True. For experiment data use False.   
    train_test_repeats: 2 #100 #How many train test splits. Set this to 1 if chronological_order is True -> Repeating with the same train-test split makes no sense.
    predict: seq #Do we predict event or seq. 
    normalize: True #Do we apply enhacer "standard" regular expression normalization.  
  # Hdfs:
  #   filename: "/hdfs/HDFS.log"
  #   labels_file_name: "/hdfs/anomaly_label.csv"
  #   loader: "HDFSLoader"
  #   proportion: 1/100
  #   proportion_redraws: 100
  #   test_fraction: 0.9
  #   chronological_order : False 
  #   train_test_repeats: 10
  #   predict: seq
  #   normalize: False
    # Bgl:
  #   filename: "/bgl/BGL.log"
  #   loader: "BGLLoader"
  #   proportion: 1/100 
  #   proportion_redraws: 5 
  #   test_fraction: 0.95 
  #   chronological_order : True 
  #   train_test_repeats: 1  
  #   predict: event 
  #   normalize: False 
#  Pro:
#    filename: "/profilence/*.txt"
#    loader: "ProLoader"
#  Nezha-TrainTicket:
#    filename: "/nezha/"
#    loader: "NezhaLoader"
#  Nezha-Shop:
#    filename: "/nezha/"
#    loader: "NezhaLoader"  
# Laptop does not have sufficient memory for supercomputers    
  # Tb:
  #   filename: "/thunderbird/Thunderbird.log"
  #   loader: "ThuSpiLibLoader"
  #   proportion: 1/3200
  #   proportion_redraws: 5
  #   test_fraction: 0.95
  #   chronological_order : True 
  #   train_test_repeats: 1
  #   predict: event
  #   normalize: False
  # Spirit:
  #   filename: "/spirit/spirit2.log"
  #   loader: "ThuSpiLibLoader"
  #   proportion: 1/3200
  #   proportion_redraws: 5
  #   test_fraction: 0.95
  #   chronological_order : True 
  #   train_test_repeats: 1
  #   predict: event
  #   shuffle : False
  #   normalize: False
  # Liberty:
  #   filename: "/liberty/liberty2.log"
  #   loader: "ThuSpiLibLoader"
  #   proportion: 1/3200
  #   proportion_redraws: 5
  #   test_fraction: 0.95
  #   chronological_order : True 
  #   train_test_repeats: 1
  #   predict: event
  #   normalize: False


algos:
  - name: LR
    call: train_LR
  - name: DT
    call: train_DT
  - name: RF
    call: train_RF
  - name: SVM
    call: train_LSVM
  - name: XGB
    call: train_XGB
  - name: Kmeans
    call: train_KMeans
  - name: IsolationForrest
    call: train_IsolationForest
  - name: RarityModel
    call: train_RarityModel
  # - name: OOVDModel
  #   call: train_OOVDetector  

parsers:
  - name: Tip
    call: parse_tip
    field: e_event_tip_id
  # - name: Iplom
  #   call: parse_iplom
  #   field: e_event_iplom_id
  - name: Drain
    call: parse_drain
    field: e_event_drain_id
  - name: Pliplom
    call: parse_pliplom
    field: e_event_pliplom_id
#  - name: AEL
#    call: parse_ael
#    field: e_event_ael_id
#  - name: Spell
#    call: parse_spell
#    field: e_event_spell_id
  - name: Brain
    call: parse_brain
    field: e_event_brain_id  

#  - name: Lenma
#    call: parse_lenma
#    field: e_event_lenma_id

