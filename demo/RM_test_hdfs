#Sequence levels prediction
import sys
sys.path.append('..')
import loglead.loader as load, loglead.enhancer as er, loglead.anomaly_detection as ad
import time
import polars as pl


full_data = "/home/ubuntu/Datasets"
private_data ="../private_data"
dataset = "hdfs_s_parq" #hdfs, pro, hadoop, tb, tb-small

df = None
df_seq = None
loader = None

#df = pl.read_parquet(f"{private_data}/P4_Parsed_hdfs_events_01.parquet")
#df_seq = pl.read_parquet(f"{private_data}/P4_Parsed_hdfs_seqs_01.parquet")



#df = loader.execute()
#if dataset!="hadoop":
#    df = loader.reduce_dataframes(frac=0.02)
#df_seq = loader.df_sequences


df = pl.read_parquet(f"{private_data}/hdfs_events_002.parquet")
df_seq = pl.read_parquet(f"{private_data}/hdfs_seqs_002.parquet")
enhancer = er.EventLogEnhancer(df)
df = enhancer.parse_drain()
df = enhancer.words()


#Collect events to sequence level as list[str]
seq_enhancer = er.SequenceEnhancer(df = df, df_sequences = df_seq)
seq_enhancer.tokens("e_words")
seq_enhancer.events("e_event_id")
#seq_enhancer.events("e_event_lenma_id")
#seq_enhancer.events("e_event_spell_id")
#seq_enhancer.embeddings("e_bert_emb")


# Suppress ConvergenceWarning
import warnings
from sklearn.exceptions import ConvergenceWarning
warnings.filterwarnings("ignore", category=ConvergenceWarning)

sad = ad.SupervisedAnomalyDetection(item_list_col="e_event_id")
sad.test_train_split (seq_enhancer.df_sequences, test_frac=0.5, new_split=True)



res = sad.train_RarityModel(threshold=50000)
res = sad.predict(custom_plot = True)
res = sad.train_RarityModel(threshold=400)
res = sad.predict(custom_plot = True)
res = sad.train_RarityModel(threshold=300)
res = sad.predict(custom_plot = True)
res = sad.train_RarityModel(threshold=200)
res = sad.predict(custom_plot = True)
res = sad.train_RarityModel(threshold=1)
res = sad.predict(custom_plot = True)

res = sad.train_IsolationForest()
res = sad.predict(custom_plot = True)



sad = ad.SupervisedAnomalyDetection(item_list_col="e_event_lenma_id")
sad.test_train_split (seq_enhancer.df_sequences, test_frac=0.5, new_split=True)
res = sad.train_RarityModel()
res = sad.predict(custom_plot = True)


sad = ad.SupervisedAnomalyDetection(item_list_col="e_event_spell_id")
sad.test_train_split (seq_enhancer.df_sequences, test_frac=0.5, new_split=True)
res = sad.train_RarityModel()
res = sad.predict(custom_plot = True)

sad = ad.SupervisedAnomalyDetection(item_list_col="e_words")
sad.test_train_split (seq_enhancer.df_sequences, test_frac=0.5, new_split=True)
res = sad.train_RarityModel()
res = sad.predict(custom_plot = True)

